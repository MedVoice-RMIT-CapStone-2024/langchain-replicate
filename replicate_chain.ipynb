{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magics to auto-reload external modules in case you are making changes to langchain while working on this notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 2,
>>>>>>> 942013578c528c27447d2d2d7a8baed9312f45b7
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a token: https://replicate.com/account\n",
    "\n",
    "from getpass import getpass\n",
    "\n",
    "REPLICATE_API_TOKEN = getpass()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 3,
>>>>>>> 942013578c528c27447d2d2d7a8baed9312f45b7
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain\n",
    "%pip install -q langchain-community\n",
    "%pip install -q langchain-core\n",
    "%pip install -q replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import Replicate\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 6,
>>>>>>> 942013578c528c27447d2d2d7a8baed9312f45b7
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "d:\\langchain-replicate\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
=======
      "c:\\Users\\AT\\Desktop\\Capstone_ML\\rep\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
>>>>>>> 942013578c528c27447d2d2d7a8baed9312f45b7
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "'{ \"Id\": 1, \"age\": 20, \"diagnosis\": \"headache\", \"gender\": \"Male\" ,\"name\": \"Alex\" } '"
      ]
     },
     "execution_count": 5,
=======
       "'{ \"Id\": 1, \"age\": 50, \"diagnosis\": \"Type 2 Diabetes\", \"gender\": \"Male\", \"name\": \"Mr. Anderson\" } '"
      ]
     },
     "execution_count": 6,
>>>>>>> 942013578c528c27447d2d2d7a8baed9312f45b7
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = {\n",
    "    \"prompt\": \"Send a email from andreas86@telia.se to myfriend@telia.se where you discuss the weather. In the body, describe the current weather in Stockholm as detailed as possible.\\n\\nRespond with json that adheres to the following jsonschema:\\n\\n{jsonschema}\",\n",
    "    \"grammar\": \"\",\n",
    "    \"jsonschema\": \"{\\n \\\"type\\\": \\\"object\\\", \\n \\\"properties\\\": {\\n \\\"Id\\\" : {  \\\"type\\\" : \\\"integer\\\"}, \\n \\\"name\\\" : {\\n \\\"type\\\" : \\\"string\\\"}, \\n \\\"age\\\" : {\\n \\\"type\\\" : \\\"integer\\\"}, \\n \\\"gender\\\" : {\\n \\\"type\\\" : \\\"string\\\" }, \\n \\\"diagnosis\\\" : {\\n \\\"type\\\" : \\\"string\\\" }} }\"\n",
    "}\n",
    "\n",
    "llm = Replicate(\n",
    "    model=\"andreasjansson/llama-2-13b-chat-gguf:60ec5dda9ff9ee0b6f786c9d1157842e6ab3cc931139ad98fe99e08a35c5d4d4\",\n",
    "    model_kwargs={\"temperature\": 0.75, \"max_length\": 500, \"top_p\": 1, \"jsonschema\": \"{\\n \\\"type\\\": \\\"object\\\", \\n \\\"properties\\\": {\\n \\\"Id\\\" : {  \\\"type\\\" : \\\"integer\\\"}, \\n \\\"name\\\" : {\\n \\\"type\\\" : \\\"string\\\"}, \\n \\\"age\\\" : {\\n \\\"type\\\" : \\\"integer\\\"}, \\n \\\"gender\\\" : {\\n \\\"type\\\" : \\\"string\\\" }, \\n \\\"diagnosis\\\" : {\\n \\\"type\\\" : \\\"string\\\" }} }\"},\n",
    ")\n",
    "prompt = \"\"\"\n",
    "System: You are an AI that summarizes medical conversations into a structured JSON format. Given the medical transcript below, provide a summary by extracting key-value pairs. Only use the information explicitly mentioned in the transcript, and you must not infer or assume any details that are not directly stated.\n",
    "Speaker 1: Good morning, Nurse. Could you please update me on the status of our patient, Mr. Anderson?\n",
    "Speaker 2: Good morning, Doctor. Mr. Anderson's blood pressure has stabilized at 100/70. His blood glucose level this morning was 8 mmol/L.\n",
    "Speaker 1: That's good to hear. Has he taken his medication for the morning?\n",
    "Speaker 2: Yes, Doctor. He took his Metformin at 7 AM, as prescribed.\n",
    "Speaker 1: Excellent. Please continue to monitor his vitals and let me know if there are any significant changes.\n",
    "Speaker 2: Absolutely, Doctor. I'll keep you updated.\n",
    "\"\"\"\n",
    "llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 7,
>>>>>>> 942013578c528c27447d2d2d7a8baed9312f45b7
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{\n",
      "\"name\": \"Mr. Anderson\",\n",
      "\"age\": null,\n",
      "\"gender\": null,\n",
      "\"diagnosis\": [],\n",
      "\"treatment\": [{\"name\": \"Metformin\", \"prescription\": \"as prescribed\"}],\n",
      "\"vital\": [{\"name\": \"blood pressure\", \"value\": \"100/70\", \"units\": null}, {\"name\": \"blood glucose level\", \"value\": \"8\", \"units\": \"mmol/L\"}]\n",
      "}"
=======
      "{ \"Id\": 1, \"age\": 20, \"diagnosis\": \"headache\", \"gender\": \"male\" ,\"name\": \"Alex\" }"
>>>>>>> 942013578c528c27447d2d2d7a8baed9312f45b7
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm = Replicate(\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    model=\"meta/meta-llama-3-70b-instruct\",\n",
    "    model_kwargs={\n",
    "      \"top_k\": 0,\n",
    "      \"top_p\": 0.9,\n",
    "      \"max_tokens\": 512,\n",
    "      \"min_tokens\": 0,\n",
    "      \"temperature\": 0.6,\n",
    "      \"length_penalty\": 1,\n",
    "      \"stop_sequences\": \"<|end_of_text|>,<|eot_id|>\",\n",
    "      \"presence_penalty\": 1.15,\n",
    "      \"log_performance_metrics\": False}, \n",
    ")\n",
    "json_schema=\"\"\"{\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"name\": {\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    \"age\": {\n",
    "      \"type\": \"integer\"\n",
    "    },\n",
    "    \"gender\": {\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    \"diagnosis\": {\n",
    "      \"type\": \"array\",\n",
    "      \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"name\": {\n",
    "            \"type\": \"string\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"name\"]\n",
    "      }\n",
    "    },\n",
    "    \"treatment\": {\n",
    "      \"type\": \"array\",\n",
    "      \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"name\": {\n",
    "            \"type\": \"string\"\n",
    "          },\n",
    "          \"prescription\": {\n",
    "            \"type\": \"string\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"name\", \"prescription\"]\n",
    "      }\n",
    "    },\n",
    "    \"vital\": {\n",
    "      \"type\": \"array\",\n",
    "      \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"name\": {\n",
    "            \"type\": \"string\"\n",
    "          },\n",
    "          \"value\": {\n",
    "            \"type\": \"string\"\n",
    "          },\n",
    "          \"units\": {\n",
    "            \"type\": \"string\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"name\", \"value\", \"units\"]\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"name\", \"gender\", \"treatment\", \"vital\"]\n",
    "}\"\"\"\n",
    "prompt = f\"\"\"\n",
    "System: You are an AI that summarizes medical conversations into a structured JSON format like this{json_schema}. Given the medical transcript below, provide a summary by extracting key-value pairs. Only use the information explicitly mentioned in the transcript, and you must not infer or assume any details that are not directly stated, and strictly follow what the json schema required, and print the json schema only.\n",
    "User: \n",
    "Speaker 1: Good morning, Nurse. Could you please update me on the status of our patient, Mr. Anderson?\n",
    "Speaker 2: Good morning, Doctor. Mr. Anderson's blood pressure has stabilized at 100/70. His blood glucose level this morning was 8 mmol/L.\n",
    "Speaker 1: That's good to hear. Has he taken his medication for the morning?\n",
    "Speaker 2: Yes, Doctor. He took his Metformin at 7 AM, as prescribed.\n",
    "Speaker 1: Excellent. Please continue to monitor his vitals and let me know if there are any significant changes.\n",
    "Speaker 2: Absolutely, Doctor. I'll keep you updated.\n",
    "Assistant:\n",
    "\"\"\"\n",
    "_ = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.10.11"
=======
   "version": "3.12.3"
>>>>>>> 942013578c528c27447d2d2d7a8baed9312f45b7
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
